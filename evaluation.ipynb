{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install nltk rouge-score pandas\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoHXkYOSyb8A",
        "outputId": "7d6961c5-0aa0-47c5-f715-302f5184b607"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiL3tURCxxc5",
        "outputId": "0418ff41-b565-44d4-afac-4ebdcb46eb11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries after installation\n",
        "import pandas as pd\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge_score import rouge_scorer  # Use the correct import for the ROUGE score\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "7964PMQjyxIx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/synthetic_reviews.csv')"
      ],
      "metadata": {
        "id": "rQRJPAS2yDiq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the DataFrame has the expected columns\n",
        "if 'synthetic_review' not in data.columns or 'original_prompt' not in data.columns:\n",
        "    raise ValueError(\"CSV must contain 'synthetic_review' and 'original_prompt' columns.\")\n"
      ],
      "metadata": {
        "id": "XkY1g3QFyLmf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the synthetic reviews and original prompts\n",
        "synthetic_reviews = data['synthetic_review'].tolist()\n",
        "original_prompts = data['original_prompt'].tolist()  # This could serve as reference if needed\n"
      ],
      "metadata": {
        "id": "MjjlMqLSzG9H"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. BLEU Score Calculation\n",
        "def calculate_bleu(synthetic_reviews, reference_reviews):\n",
        "    bleu_scores = []\n",
        "    for synth, ref in zip(synthetic_reviews, reference_reviews):\n",
        "        # Tokenize the sentences\n",
        "        reference = ref.split()\n",
        "        candidate = synth.split()\n",
        "        score = sentence_bleu([reference], candidate)\n",
        "        bleu_scores.append(score)\n",
        "    return sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0\n",
        "\n",
        "# 2. ROUGE Score Calculation\n",
        "def calculate_rouge(synthetic_reviews, reference_reviews):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    scores = [scorer.score(ref, synth) for ref, synth in zip(reference_reviews, synthetic_reviews)]\n",
        "    avg_scores = {key: sum(score[key].fmeasure for score in scores) / len(scores) for key in scores[0].keys()}\n",
        "    return avg_scores\n",
        "\n",
        "# 3. Diversity Measurement\n",
        "def calculate_diversity(reviews):\n",
        "    n_grams = Counter()\n",
        "    for review in reviews:\n",
        "        tokens = review.split()\n",
        "        n_grams.update(Counter(tokens))\n",
        "    distinct_n = len(n_grams)\n",
        "    total_n = sum(n_grams.values())\n",
        "    diversity_score = distinct_n / total_n if total_n > 0 else 0\n",
        "    return diversity_score\n"
      ],
      "metadata": {
        "id": "G2KPqIxvzIlG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate synthetic reviews\n",
        "bleu_score = calculate_bleu(synthetic_reviews, original_prompts)  # Using original prompts as reference\n",
        "rouge_score = calculate_rouge(synthetic_reviews, original_prompts)  # Same here\n",
        "diversity_score = calculate_diversity(synthetic_reviews)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_fdyWpJzLe_",
        "outputId": "78564399-8972-4023-e6ee-4c523380d9bc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print evaluation results\n",
        "print(f\"BLEU Score: {bleu_score:.4f}\")\n",
        "print(f\"ROUGE Score: {rouge_score}\")\n",
        "print(f\"Diversity Score: {diversity_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3y2pHocPzM7X",
        "outputId": "ee257989-9a4d-40a3-d41f-fa8b9aef5fad"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.4494\n",
            "ROUGE Score: {'rouge1': 0.6236275041239976, 'rouge2': 0.6033162948343247, 'rougeL': 0.6236275041239976}\n",
            "Diversity Score: 0.4255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pGLiu2EezPzO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}